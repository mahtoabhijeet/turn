{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcrEbJtjOxnGi9+L8WKT36",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahtoabhijeet/turn/blob/main/Untitled25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6BMJhA5MG1C",
        "outputId": "32936639-2a2d-4e2a-83bc-6438538fe930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitarray\n",
            "  Downloading bitarray-3.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Downloading bitarray-3.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (332 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.9/332.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitarray\n",
            "Successfully installed bitarray-3.7.1\n"
          ]
        }
      ],
      "source": [
        "# Cell 1 - imports + helpers\n",
        "!pip install bitarray  # optional for bit manipulation performance\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from itertools import combinations\n",
        "from collections import Counter\n",
        "import math\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# small vocab - characters or tiny wordlist\n",
        "vocab = list(\"abcdefghijklmnopqrstuvwxyz '.,\")\n",
        "V = len(vocab)\n",
        "stoi = {c:i for i,c in enumerate(vocab)}\n",
        "itos = {i:c for c,i in stoi.items()}\n",
        "\n",
        "def text_to_tokens(text, maxlen=None):\n",
        "    toks = [stoi.get(c,0) for c in text.lower()]\n",
        "    if maxlen:\n",
        "        toks = toks[:maxlen]\n",
        "    return toks\n",
        "\n",
        "def tokens_to_text(toks):\n",
        "    return ''.join(itos[t] for t in toks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 - define boolean polynomial utilities (GF(2))\n",
        "# Represent polynomials as sets of monomials; each monomial is a tuple of variable indices.\n",
        "# variables = state_bits (0..S-1) then input bits (S..S+V-1) (we use one-hot input)\n",
        "def eval_poly_gf2(monomials, var_vector):\n",
        "    # var_vector: numpy array of 0/1 ints\n",
        "    res = 0\n",
        "    for mono in monomials:\n",
        "        prod = 1\n",
        "        for idx in mono:\n",
        "            prod &= var_vector[idx]\n",
        "            if prod == 0:\n",
        "                break\n",
        "        res ^= prod  # addition mod 2 (XOR)\n",
        "    return res\n",
        "\n",
        "def eval_polynomials_gf2(polys, var_vector):\n",
        "    # polys: list of monomial-sets, one per output bit\n",
        "    return np.array([eval_poly_gf2(p, var_vector) for p in polys], dtype=np.uint8)\n"
      ],
      "metadata": {
        "id": "FuWQlHfEMXmE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 - small RNN spec + random-evolution search\n",
        "S = 16           # number of state bits\n",
        "V_in = V         # input one-hot size\n",
        "total_vars = S + V_in\n",
        "\n",
        "# random initial population of polynomial sets\n",
        "def random_polys(num_output_bits, max_monomials=8, max_degree=2):\n",
        "    polys = []\n",
        "    for _ in range(num_output_bits):\n",
        "        mset = []\n",
        "        nmons = random.randint(1, max_monomials)\n",
        "        for _ in range(nmons):\n",
        "            deg = random.randint(1, max_degree)\n",
        "            mono = tuple(sorted(random.sample(range(total_vars), deg)))\n",
        "            mset.append(mono)\n",
        "        polys.append(set(mset))\n",
        "    return polys\n",
        "\n",
        "def rnn_step(state, input_onehot, polys):\n",
        "    # build var vector = [state_bits..., input_bits...]\n",
        "    var_vec = np.concatenate([state, input_onehot])\n",
        "    nxt = eval_polynomials_gf2(polys, var_vec)\n",
        "    return nxt\n",
        "\n",
        "# decode function: map state bits -> token by small readout table (learned / random map)\n",
        "def decode_state_to_token(state, mapping):\n",
        "    # mapping: dict from tuple(state_bits) -> token index; fallback: argmax bit\n",
        "    key = tuple(state.tolist())\n",
        "    if key in mapping:\n",
        "        return mapping[key]\n",
        "    else:\n",
        "        # fallback: token from highest bit set else 0\n",
        "        idx = int(np.argmax(state))\n",
        "        return idx % V  # coerce to vocab\n"
      ],
      "metadata": {
        "id": "5dfkDhXjMcbm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 - evolutionary search to reproduce one short sentence\n",
        "target = \"hello.\"\n",
        "tokens = text_to_tokens(target)\n",
        "T = len(tokens)\n",
        "\n",
        "# initial mapping: random map from some states to tokens\n",
        "mapping = {}\n",
        "# simple objective: fraction of characters matched over sequence\n",
        "def score_polys(polys, mapping):\n",
        "    state = np.zeros(S, dtype=np.uint8)\n",
        "    correct = 0\n",
        "    for t in range(T):\n",
        "        # input is one-hot of previous token (or start token)\n",
        "        inp = np.zeros(V, dtype=np.uint8)\n",
        "        prev = tokens[t-1] if t>0 else 0\n",
        "        inp[prev] = 1\n",
        "        state = rnn_step(state, inp, polys)\n",
        "        out = decode_state_to_token(state, mapping)\n",
        "        if out == tokens[t]:\n",
        "            correct += 1\n",
        "    return correct / T\n",
        "\n",
        "# hill-climb\n",
        "best_polys = random_polys(S, max_monomials=6, max_degree=2)\n",
        "# random mapping initialization\n",
        "for i in range(256):\n",
        "    mapping[tuple(np.random.randint(0,2,S))] = random.randrange(V)\n",
        "best_score = score_polys(best_polys, mapping)\n",
        "print(\"init score\", best_score)\n",
        "\n",
        "for it in range(1000):\n",
        "    # mutate: flip/add/remove a monomial in a random output bit\n",
        "    cand = [set(p) for p in best_polys]\n",
        "    outi = random.randrange(S)\n",
        "    if random.random() < 0.5 and len(cand[outi])>0:\n",
        "        cand[outi].pop()\n",
        "    else:\n",
        "        deg = random.choice([1,2])\n",
        "        mono = tuple(sorted(random.sample(range(total_vars), deg)))\n",
        "        cand[outi].add(mono)\n",
        "    sc = score_polys(cand, mapping)\n",
        "    if sc > best_score:\n",
        "        best_score = sc\n",
        "        best_polys = cand\n",
        "        print(\"iter\", it, \"new best\", best_score)\n",
        "        if best_score == 1.0:\n",
        "            break\n",
        "\n",
        "print(\"final best score\", best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id_iGMAYMeG_",
        "outputId": "5ee1078c-53db-460c-82e8-fa7d6ece0408"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init score 0.0\n",
            "iter 535 new best 0.16666666666666666\n",
            "iter 951 new best 0.3333333333333333\n",
            "final best score 0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 - imports\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# vocab setup\n",
        "vocab = list(\"abcdefghijklmnopqrstuvwxyz '.,\")\n",
        "V = len(vocab)\n",
        "stoi = {c:i for i,c in enumerate(vocab)}\n",
        "itos = {i:c for c,i in stoi.items()}\n"
      ],
      "metadata": {
        "id": "3-htszGzNDPd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 - polynomial gate utils (same GF(2) machinery)\n",
        "def eval_poly_gf2(monomials, var_vector):\n",
        "    res = 0\n",
        "    for mono in monomials:\n",
        "        prod = 1\n",
        "        for idx in mono:\n",
        "            prod &= var_vector[idx]\n",
        "            if prod == 0: break\n",
        "        res ^= prod  # XOR\n",
        "    return res\n",
        "\n",
        "def eval_polynomials_gf2(polys, var_vector):\n",
        "    return np.array([eval_poly_gf2(p, var_vector) for p in polys], dtype=np.uint8)\n",
        "\n",
        "def rnn_step(state, input_onehot, polys):\n",
        "    var_vec = np.concatenate([state, input_onehot])\n",
        "    nxt = eval_polynomials_gf2(polys, var_vec)\n",
        "    return nxt\n"
      ],
      "metadata": {
        "id": "VpWdLgScNH1i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 - generate dataset (state trajectories)\n",
        "target = \"hello.\"\n",
        "tokens = [stoi[c] for c in target]\n",
        "\n",
        "def generate_trajectory(polys, tokens):\n",
        "    states = []\n",
        "    state = np.zeros(S, dtype=np.uint8)\n",
        "    for t in range(len(tokens)):\n",
        "        inp = np.zeros(V, dtype=np.uint8)\n",
        "        prev = tokens[t-1] if t > 0 else 0\n",
        "        inp[prev] = 1\n",
        "        state = rnn_step(state, inp, polys)\n",
        "        states.append(state.copy())\n",
        "    return np.array(states)\n",
        "\n",
        "states = generate_trajectory(best_polys, tokens)  # shape (T,S)\n",
        "print(\"Trajectory shape:\", states.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn4Ncf3oNNyT",
        "outputId": "aa1099d1-597a-41de-b54d-21d0f8e0e4b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trajectory shape: (6, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 - trainable readout\n",
        "class Readout(nn.Module):\n",
        "    def __init__(self, S, V):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(S, V)\n",
        "    def forward(self, x):\n",
        "        return self.lin(x.float())\n",
        "\n",
        "readout = Readout(S, V)\n",
        "opt = optim.Adam(readout.parameters(), lr=0.05)\n",
        "lossfn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Prepare tensors\n",
        "X = torch.tensor(states, dtype=torch.float32)\n",
        "Y = torch.tensor(tokens, dtype=torch.long)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(200):\n",
        "    logits = readout(X)\n",
        "    loss = lossfn(logits, Y)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    if epoch % 50 == 0:\n",
        "        pred = logits.argmax(dim=1)\n",
        "        acc = (pred == Y).float().mean().item()\n",
        "        print(epoch, \"loss\", loss.item(), \"acc\", acc)\n",
        "\n",
        "# Final evaluation\n",
        "pred = readout(X).argmax(dim=1).tolist()\n",
        "decoded = ''.join(itos[i] for i in pred)\n",
        "print(\"Decoded sequence:\", decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ4nNsluNYER",
        "outputId": "3d411c5e-731c-4751-b577-8b70b36dae3b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss 3.335249900817871 acc 0.0\n",
            "50 loss 0.16549085080623627 acc 1.0\n",
            "100 loss 0.05803671106696129 acc 1.0\n",
            "150 loss 0.03302683308720589 acc 1.0\n",
            "Decoded sequence: hello.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 - imports\n",
        "import numpy as np, random, torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "random.seed(0); np.random.seed(0); torch.manual_seed(0)\n",
        "\n",
        "# Vocab setup (reuse previous)\n",
        "vocab = list(\"abcdefghijklmnopqrstuvwxyz '.,\")\n",
        "V = len(vocab)\n",
        "stoi = {c:i for i,c in enumerate(vocab)}\n",
        "itos = {i:c for c,i in stoi.items()}\n"
      ],
      "metadata": {
        "id": "VBUlqTuyNm0X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 - GF(2) polynomial utilities\n",
        "def eval_poly_gf2(monomials, var_vector):\n",
        "    res = 0\n",
        "    for mono in monomials:\n",
        "        prod = 1\n",
        "        for idx in mono:\n",
        "            prod &= var_vector[idx]\n",
        "            if prod == 0: break\n",
        "        res ^= prod  # XOR\n",
        "    return res\n",
        "\n",
        "def eval_polynomials_gf2(polys, var_vector):\n",
        "    return np.array([eval_poly_gf2(p, var_vector) for p in polys], dtype=np.uint8)\n",
        "\n",
        "def rnn_step(state, input_onehot, polys):\n",
        "    var_vec = np.concatenate([state, input_onehot])\n",
        "    return eval_polynomials_gf2(polys, var_vec)\n"
      ],
      "metadata": {
        "id": "k8e-2qRTNoLx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 - build random polynomial network\n",
        "S = 16\n",
        "total_vars = S + V\n",
        "\n",
        "def random_polys(num_output_bits, max_monomials=8, max_degree=2):\n",
        "    polys = []\n",
        "    for _ in range(num_output_bits):\n",
        "        mset = []\n",
        "        nmons = random.randint(1, max_monomials)\n",
        "        for _ in range(nmons):\n",
        "            deg = random.randint(1, max_degree)\n",
        "            mono = tuple(sorted(random.sample(range(total_vars), deg)))\n",
        "            mset.append(mono)\n",
        "        polys.append(set(mset))\n",
        "    return polys\n",
        "\n",
        "polys = random_polys(S, max_monomials=6, max_degree=2)\n"
      ],
      "metadata": {
        "id": "AgoFNBogNtnR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 - dataset of multiple sentences\n",
        "sentences = [\"hello.\", \"hi.\", \"the cat.\", \"the dog.\"]\n",
        "tokensets = [[stoi[c] for c in s] for s in sentences]\n",
        "\n",
        "def generate_trajectory(polys, tokens):\n",
        "    states = []\n",
        "    state = np.zeros(S, dtype=np.uint8)\n",
        "    for t in range(len(tokens)):\n",
        "        inp = np.zeros(V, dtype=np.uint8)\n",
        "        prev = tokens[t-1] if t > 0 else 0\n",
        "        inp[prev] = 1\n",
        "        state = rnn_step(state, inp, polys)\n",
        "        states.append(state.copy())\n",
        "    return np.array(states)\n",
        "\n",
        "# Build dataset\n",
        "X_list, Y_list = [], []\n",
        "for toks in tokensets:\n",
        "    states = generate_trajectory(polys, toks)\n",
        "    X_list.append(states)\n",
        "    Y_list.append(toks)\n",
        "\n",
        "X = torch.tensor(np.vstack(X_list), dtype=torch.float32)\n",
        "Y = torch.tensor(np.hstack(Y_list), dtype=torch.long)\n",
        "print(\"Dataset shape:\", X.shape, Y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgC5edt5NxVc",
        "outputId": "b6a0ec8d-849c-4084-dbca-503c0f4e5bfd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: torch.Size([25, 16]) torch.Size([25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 - trainable readout across all sentences\n",
        "class Readout(nn.Module):\n",
        "    def __init__(self, S, V):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(S, V)\n",
        "    def forward(self, x): return self.lin(x.float())\n",
        "\n",
        "readout = Readout(S, V)\n",
        "opt = optim.Adam(readout.parameters(), lr=0.05)\n",
        "lossfn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(300):\n",
        "    logits = readout(X)\n",
        "    loss = lossfn(logits, Y)\n",
        "    opt.zero_grad(); loss.backward(); opt.step()\n",
        "    if epoch % 50 == 0:\n",
        "        pred = logits.argmax(dim=1)\n",
        "        acc = (pred == Y).float().mean().item()\n",
        "        print(epoch, \"loss\", round(loss.item(),3), \"acc\", round(acc,3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO-lqfe3N066",
        "outputId": "a9adf2fe-7bae-454a-c171-1dc56566f420"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss 3.388 acc 0.08\n",
            "50 loss 0.871 acc 0.68\n",
            "100 loss 0.691 acc 0.68\n",
            "150 loss 0.639 acc 0.68\n",
            "200 loss 0.617 acc 0.68\n",
            "250 loss 0.606 acc 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 - check decoding of each sentence separately\n",
        "with torch.no_grad():\n",
        "    for s, toks in zip(sentences, tokensets):\n",
        "        states = generate_trajectory(polys, toks)\n",
        "        logits = readout(torch.tensor(states, dtype=torch.float32))\n",
        "        pred = logits.argmax(dim=1).tolist()\n",
        "        decoded = ''.join(itos[i] for i in pred)\n",
        "        print(\"Target:\", s, \"Decoded:\", decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVJCQaPEN60Q",
        "outputId": "c19e43bc-fe82-4a9d-a861-56705624bb7d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: hello. Decoded: te lo.\n",
            "Target: hi. Decoded: te \n",
            "Target: the cat. Decoded: the lath\n",
            "Target: the dog. Decoded: the log.\n"
          ]
        }
      ]
    }
  ]
}